{"Questions": [
{ "Id":"1",
"Question": "Назовите основные структуры данных в Pandas:",
"Explanation": "Series представляет собой одномерный индексированный массив данных некоторого фиксированного типа. DataFrame – это двухмерная структура данных, представляющая собой таблицу, каждый столбец которой содержит данные одного типа." , 
"Choices":
[ 
 {"Choice": "DataSeries", "Right": "0" }, 
 {"Choice": "DataFrame", "Right": "1" }, 
 {"Choice": "DataType", "Right": "0" }, 
 {"Choice": "Series", "Right": "1" }, 
 {"Choice": "CsvFrame", "Right": "0" }
]
},

{ "Id":"2", 
"Question": "Выберите верные утверждения по поводу представленя данных в DataFrame", 
"Explanation": "Индексация строк в DataFrame начинается с 0. Столбцы представляют признаки объектов, а строки - их экземпляры. Типы данных pandas и python отличаются, в основном способом их внутреннего хранения. В pandas используются как объекты, так и примитивные типы (int, float, bool и т.д.), это позволяет повысить производительность обработки больших массивов данных." , 
"Choices":
[ 
 {"Choice": "Индексация строк начинается с 1", "Right": "0" }, 
 {"Choice": "Строки представляют отдельные объекты", "Right": "1" }, 
 {"Choice": "Столбцы представляют признаки объектов", "Right": "1" }, 
 {"Choice": "Строки представляют признаки объектов", "Right": "0" }, 
 {"Choice": "Типы данных pandas совпадают с типами данных python", "Right": "0" }
]
},

{ "Id":"3", 
"Question": "Для получения общей информации о DataFrame и типах данных признаков используется метод:", 
"Explanation": "Метод head используется для вывода нескольких (по умолчанию 5) строк таблицы, describe -  показывает основные статистические характеристики данных по каждому числовому признаку, groupby применяется для группировки данных, map позволяет применить функцию к каждой ячейке столбца или строки, а также произвести замену значений при помощи словаря." , 
"Choices":
[ 
 {"Choice": "head()", "Right": "0" }, 
 {"Choice": "describe()", "Right": "0" }, 
 {"Choice": "groupby()", "Right": "0" }, 
 {"Choice": "info()", "Right": "1" }, 
 {"Choice": "map()", "Right": "0" }
]
},

{ "Id":"4", 
"Question": "Выберите тип графика, который метод plot класса DataFrame строить не позволяет:", 
"Explanation": "Для построения тепловых карт признаков стоит воспользоваться функцией из библиотеки seaborn." , 
"Choices":
[ 
 {"Choice": "Столбики (bar)", "Right": "0" }, 
 {"Choice": "Гистограмма (hist) ", "Right": "0" }, 
 {"Choice": "Тепловая карта (heatmap)", "Right": "1" }, 
 {"Choice": "Оценка плотности распределения (kde)", "Right": "0" }, 
 {"Choice": "Круговая диаграмма (pie)", "Right": "0" }
]
},

{ "Id":"5", 
"Question": "Выберите верные утверждения:", 
"Explanation": "Метод pairplot действительно отображает гистограмму распределений для каждого признака, но для взаимных зависимостей строятся обычные точечные диаграммы scatterplot.", 
"Choices":
[ 
 {"Choice": "Метод pairplot строит матрицу гистограмм распределения признаков", "Right": "0" }, 
 {"Choice": "Метод distplot строит матрицу гистограмм распределения признаков", "Right": "0" }, 
 {"Choice": "Метод pairplot по умолчанию строит гистограмму распределения и кривую kde", "Right": "0" }, 
 {"Choice": "Метод distplot по умолчанию строит гистограмму распределения и кривую kde", "Right": "1" }
]
},

{ "Id":"6", 
"Question": "По умолчанию метод boxplot строит box, в котором:", 
"Explanation": "По умолчанию boxplot отображает медиану, интерквартильный размах распределения (Q1=25%, Q3=75%) и усы [Q1- 1.5 x IQR ; Q3 + 1.5 x IQR]." , 
"Choices":
[ 
 {"Choice": "Линия в box соответствует матожиданию ряда, границы box: +- сигма, усы +- 3 сигма", "Right": "0" }, 
 {"Choice": "Линия в box - медиана ряда, границы box: +- сигма, усы +- 3 сигма", "Right": "0" }, 
 {"Choice": "Линия в box - матожидании ряда, границы box: квантили Q1 и Q3, усы +- 3 сигма", "Right": "0" }, 
 {"Choice": "Линия в box - медиана ряда, границы box: квантили Q1 и Q3, усы: Q1- 1.5 x IQR ; Q3 + 1.5 x IQR", "Right": "1" }, 
 {"Choice": "Линия в box - матожидание ряда, границы box: квантили Q1 и Q3, усы: +- Q1- 1.5 x IQR ; Q3 + 1.5 x IQR", "Right": "0" }
]
},

{ "Id":"7", 
"Question": "Какие объекты plotly служат для представления массива данных trace?", 
"Explanation": "Объект Figure в plotly инициализируется с указанием массива данных (trace) и параметров разметки (layout). Scatter используется для построения обычных графиков, Bar для столбиков." , 
"Choices":
[ 
 {"Choice": "Scatter", "Right": "1" }, 
 {"Choice": "Layout", "Right": "0" }, 
 {"Choice": "Bar", "Right": "1" }, 
 {"Choice": "Figure", "Right": "0" }, 
 {"Choice": "GraphObject", "Right": "0" }
]
},

{ "Id":"8", 
"Question": "Какие достоинства у метода t-SNE?", 
"Explanation": "Несмотря на высокую вычислительную сложность и неустойчивость по отношению к random_seed, метод t-SNE позволяет получить хорошее общее представление о данных." , 
"Choices":
[ 
 {"Choice": "Низкая вычислительная сложность", "Right": "0" }, 
 {"Choice": "Возможность наглядной проекции многомерных данных в 2D или 3D пространство", "Right": "1" }, 
 {"Choice": "Устойчивось по отношению к источнику случайных числел random_seed", "Right": "0" }, 
 {"Choice": "Визуальная кластеризация данных", "Right": "1" }, 
 {"Choice": "Возможность проекции в 4D пространство", "Right": "0" }
]
},

{ "Id":"9", 
"Question": "Классификация – это", 
"Explanation": "Классификация – это отнесение объекта к одной из категорий на основании его признаков." , 
"Choices":
[ 
 {"Choice": "Прогнозирование количественного признака объекта на основании прочих его признаков ", "Right": "0" }, 
 {"Choice": "Отнесение объекта к одной из категорий на основании его признаков", "Right": "1" }, 
 {"Choice": "Разбиение множества объектов на группы на основании признаков этих объектов так, чтобы внутри групп объекты были похожи между собой, а вне одной группы – менее похожи", "Right": "0" },
 {"Choice": "Поиск объектов, непохожих на все остальные в выборке, либо на какую-то группу объектов", "Right": "0" }
]
},

{ "Id":"10", 
"Question": "В основе популярных алгоритмов построения дерева решений, таких как Id3 и C4.5, лежит принцип", 
"Explanation": " " , 
"Choices":
[ 
 {"Choice": "Жадной минимизации прироста информации", "Right": "0" }, 
 {"Choice": "Ленивых (отложенных) вычислений прироста энтропии", "Right": "0" }, 
 {"Choice": "Жадной максимизации прироста информации", "Right": "1" }, 
 {"Choice": "Повышение метрики P по мере накопления опыта E", "Right": "0" }
]
},

{ "Id":"11", 
"Question": "Метод ближайших соседей", 
"Explanation": "" , 
"Choices":
[ 
 {"Choice": "Использует ленивый подход, вычисления осуществляются на этапе классификации", "Right": "1" }, 
 {"Choice": "Слабо изученный метод, неоптимальный на больших выборках", "Right": "0" }, 
 {"Choice": "Не требует масштабирования признаков", "Right": "0" }, 
 {"Choice": "Может плохо работать в зависимости от веса соседей", "Right": "1" }, 
 {"Choice": "На практике заменяется приближенными методами", "Right": "1" }
]
},

{ "Id":"12", 
"Question": "Ограничения линейной модели включают в себя:", 
"Explanation": "При нормальном центрированном распределении ошибки МНК и метод максимального правдоподобия дают одинаковую оценку." , 
"Choices":
[ 
 {"Choice": "Ни один из элементов вектора весовых коэффициентов не может равняться нулю", "Right": "0" }, 
 {"Choice": "Матожидание случайных ошибок не равно нулю", "Right": "0" }, 
 {"Choice": "Дисперсия случайных ошибок постоянна или изменяется по известному закону", "Right": "0" }, 
 {"Choice": "Корреляция случайных ошибок равна нулю", "Right": "1" }, 
 {"Choice": "МНК дает лучшую оценку коэффициентов, чем оценка максимального правдоподобия", "Right": "0" }
]
},

{ "Id":"13", 
"Question": "К чему приводит переобучение модели?", 
"Explanation": " " , 
"Choices":
[ 
 {"Choice": "Увеличению bias", "Right": "0" }, 
 {"Choice": "Уменьшению bias", "Right": "1" }, 
 {"Choice": "Увеличению var", "Right": "1" }, 
 {"Choice": "Уменьшению var", "Right": "0" }, 
 {"Choice": "Увеличению неустранимой ошибки", "Right": "0" }, 
 {"Choice": "Уменьшению неустранимой ошибки", "Right": "0" }
]
},

{ "Id":"14", 
"Question": "Выберите верное утверждение относительно логистической регрессии.", 
"Explanation": " " , 
"Choices":
[ 
 {"Choice": "Является частным случаем линейного классификатора", "Right": "1" }, 
 {"Choice": "Значения целевого признака не могут выходить за диапазон [0 ; 1]", "Right": "0" }, 
 {"Choice": "Отношение вероятностей лежит в диапазоне [0 ; 1]", "Right": "0" }, 
 {"Choice": "Вероятность отнесения примера к классу '+' находится как сигмоид-преобразование линейной комбинации вектора весов модели и вектора признаков", "Right": "1" }
]
}
 ]
}
